{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862752c0",
   "metadata": {},
   "source": [
    "# **COMPLETE GUIDE OF DATA PRE-PROCESSING : WHAT, WHY & HOW TO HANDLE MESSY DATA**\n",
    "\n",
    "### Let's prepare our data for better analysis and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc8794",
   "metadata": {},
   "source": [
    "## **A. Learning Objectives**\n",
    "\n",
    "* **Get a clearer idea of why data preprocessing actually matters**\n",
    "\n",
    "* **Learn how to handle different data preprocessing techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35acb7",
   "metadata": {},
   "source": [
    "## **B. Background Theory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc017b00",
   "metadata": {},
   "source": [
    "\n",
    "The quality of your data plays a big role in how accurate your analysis and models turn out. Why? Because raw data usually comes with a bunch of issues—like errors, inconsistencies, or stuff that’s just not useful—which can mess up your results and lead to misleading insights. That’s where data preprocessing comes in. It’s basically the step where you clean and organize your data so it’s ready to be used properly.\n",
    "\n",
    "### **What is Data Pre-Processing ?**\n",
    "\n",
    "Data preprocessing is the process of preparing raw data so it can be used effectively in machine learning models. Think of it like cleaning and organizing ingredients before cooking a meal—if the ingredients are messy or spoiled, the final dish won’t turn out well.\n",
    "\n",
    "### **What It Involves**\n",
    "\n",
    "Here are the key steps in data preprocessing:\n",
    "\n",
    "1. Cleaning the Data\n",
    "    \n",
    "    - Fixing or removing missing values\n",
    "    \n",
    "    - Removing duplicates\n",
    "    \n",
    "    - Correcting errors or inconsistencies\n",
    "    \n",
    "2. Transforming the Data\n",
    "\n",
    "    - Scaling values (e.g., making sure all numbers are on a similar scale)\n",
    "    \n",
    "    - Encoding categories (e.g., turning \"Yes\"/\"No\" into 1/0)\n",
    "    \n",
    "    - Normalizing or standardizing data\n",
    "\n",
    "3. Reducing the Data\n",
    "\n",
    "    - Selecting only the most useful features\n",
    "\n",
    "    - Removing irrelevant or redundant information\n",
    "\n",
    "    - Dimensionality reduction (e.g., using PCA)\n",
    "\n",
    "4. Splitting the Data\n",
    "    \n",
    "    - Dividing into training\n",
    "    \n",
    "    - validation, and test sets\n",
    "\n",
    "\n",
    "### **Why It’s Important in Machine Learning**\n",
    "\n",
    "Machine learning models learn patterns from data. If the data is messy, the model might learn the wrong patterns or get confused. Preprocessing helps:\n",
    "\n",
    "- Improve model accuracy\n",
    "\n",
    "- Speed up training\n",
    "\n",
    "- Avoid errors and bias\n",
    "\n",
    "- Make the model more generalizable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af8799",
   "metadata": {},
   "source": [
    "## **C. Practical Steps for Effective Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6fbc5e",
   "metadata": {},
   "source": [
    "let's load data set first. in this learning, we will use dataset from : Customer Churn Prediction dataset from Bharti Pasad : [view-dataset](https://www.kaggle.com/code/bhartiprasad17/customer-churn-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54227b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CustomerID       1000 non-null   int64  \n",
      " 1   Age              1000 non-null   int64  \n",
      " 2   Gender           1000 non-null   object \n",
      " 3   Tenure           1000 non-null   int64  \n",
      " 4   MonthlyCharges   1000 non-null   float64\n",
      " 5   ContractType     1000 non-null   object \n",
      " 6   InternetService  703 non-null    object \n",
      " 7   TotalCharges     1000 non-null   float64\n",
      " 8   TechSupport      1000 non-null   object \n",
      " 9   Churn            1000 non-null   object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 78.3+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "\n",
    "url_dataset = \"https://raw.githubusercontent.com/adisetiawannn/DataCraft/main/data/raw/dataset_preprocessing/customer_churn_data.csv\"\n",
    "\n",
    "df = pd.read_csv(url_dataset)\n",
    "\n",
    "# display the first five rows of the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf200765",
   "metadata": {},
   "source": [
    "### **1. Cleaning Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08adc033",
   "metadata": {},
   "source": [
    "#### 1.1 Missing Value\n",
    "\n",
    "Missing values are empty spots in your data—like blanks or NaNs—that can mess things up when training a model.\n",
    "\n",
    "- Why Fix Them?\n",
    "\n",
    "Because most machine learning models don’t like missing data. If you ignore them, your model might crash or give bad predictions.\n",
    "\n",
    "- How to Handle?\n",
    "\n",
    "    - Drop them if they’re not important\n",
    "    \n",
    "    - Fill them with something like the mean, median, or a default value\n",
    "    - Use forward/backward fill for time-based data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3d8076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have missing values in the following columns: ['InternetService']\n",
      "CustomerID         0\n",
      "Age                0\n",
      "Gender             0\n",
      "Tenure             0\n",
      "MonthlyCharges     0\n",
      "ContractType       0\n",
      "InternetService    0\n",
      "TotalCharges       0\n",
      "TechSupport        0\n",
      "Churn              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check column with missing values\n",
    "columns_with_missing = df.columns[df.isnull().any()].tolist() ; \n",
    "\n",
    "print(f\"we have missing values in the following columns:\", columns_with_missing);\n",
    "\n",
    "\n",
    "# from the info above, we can see that the InternetService column has missing values\n",
    "# then, we will drop the rows with missing values in the InternetService column\n",
    "df_drop = df.dropna(subset=['InternetService'])\n",
    "null_counts = df_drop.isnull().sum() #check null values after dropping rows\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a86536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
