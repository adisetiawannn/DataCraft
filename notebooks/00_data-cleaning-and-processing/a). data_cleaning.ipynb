{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862752c0",
   "metadata": {},
   "source": [
    "# **COMPLETE GUIDE OF DATA PRE-PROCESSING : WHAT, WHY & HOW TO HANDLE MESSY DATA**\n",
    "\n",
    "### Let's prepare our data for better analysis and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc8794",
   "metadata": {},
   "source": [
    "## **A. Learning Objectives**\n",
    "\n",
    "* **Get a clearer idea of why data preprocessing actually matters**\n",
    "\n",
    "* **Learn how to handle different data preprocessing techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35acb7",
   "metadata": {},
   "source": [
    "## **B. Background Theory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc017b00",
   "metadata": {},
   "source": [
    "\n",
    "The quality of your data plays a big role in how accurate your analysis and models turn out. Why? Because raw data usually comes with a bunch of issues—like errors, inconsistencies, or stuff that’s just not useful—which can mess up your results and lead to misleading insights. That’s where data preprocessing comes in. It’s basically the step where you clean and organize your data so it’s ready to be used properly.\n",
    "\n",
    "### **What is Data Pre-Processing ?**\n",
    "\n",
    "Data preprocessing is the process of preparing raw data so it can be used effectively in machine learning models. Think of it like cleaning and organizing ingredients before cooking a meal—if the ingredients are messy or spoiled, the final dish won’t turn out well.\n",
    "\n",
    "### **What It Involves**\n",
    "\n",
    "Here are the key steps in data preprocessing:\n",
    "\n",
    "1. Cleaning the Data\n",
    "    \n",
    "    - Fixing or removing missing values\n",
    "    \n",
    "    - Removing duplicates\n",
    "    \n",
    "    - Correcting errors or inconsistencies\n",
    "    \n",
    "2. Transforming the Data\n",
    "\n",
    "    - Scaling values (e.g., making sure all numbers are on a similar scale)\n",
    "    \n",
    "    - Encoding categories (e.g., turning \"Yes\"/\"No\" into 1/0)\n",
    "    \n",
    "    - Normalizing or standardizing data\n",
    "\n",
    "3. Reducing the Data\n",
    "\n",
    "    - Selecting only the most useful features\n",
    "\n",
    "    - Removing irrelevant or redundant information\n",
    "\n",
    "    - Dimensionality reduction (e.g., using PCA)\n",
    "\n",
    "4. Splitting the Data\n",
    "    \n",
    "    - Dividing into training\n",
    "    \n",
    "    - validation, and test sets\n",
    "\n",
    "\n",
    "### **Why It’s Important in Machine Learning**\n",
    "\n",
    "Machine learning models learn patterns from data. If the data is messy, the model might learn the wrong patterns or get confused. Preprocessing helps:\n",
    "\n",
    "- Improve model accuracy\n",
    "\n",
    "- Speed up training\n",
    "\n",
    "- Avoid errors and bias\n",
    "\n",
    "- Make the model more generalizable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af8799",
   "metadata": {},
   "source": [
    "## **C. Practical Steps for Effective Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6fbc5e",
   "metadata": {},
   "source": [
    "let's load data set first. in this learning, we will use dataset from : Customer Churn Prediction dataset from Bharti Pasad : [view-dataset](https://www.kaggle.com/code/bhartiprasad17/customer-churn-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54227b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CustomerID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tenure",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MonthlyCharges",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ContractType",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "InternetService",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "TotalCharges",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TechSupport",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Churn",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2fbbcc56-a6a5-4667-807d-ae9acf0826ca",
       "rows": [
        [
         "0",
         "1",
         "49",
         "Male",
         "4",
         "88.35",
         "Month-to-Month",
         "Fiber Optic",
         "353.4",
         "Yes",
         "Yes"
        ],
        [
         "1",
         "2",
         "43",
         "Male",
         "0",
         "36.67",
         "Month-to-Month",
         "Fiber Optic",
         "0.0",
         "Yes",
         "Yes"
        ],
        [
         "2",
         "3",
         "51",
         "Female",
         "2",
         "63.79",
         "Month-to-Month",
         "Fiber Optic",
         "127.58",
         "No",
         "Yes"
        ],
        [
         "3",
         "4",
         "60",
         "Female",
         "8",
         "102.34",
         "One-Year",
         "DSL",
         "818.72",
         "Yes",
         "Yes"
        ],
        [
         "4",
         "5",
         "42",
         "Male",
         "32",
         "69.01",
         "Month-to-Month",
         null,
         "2208.32",
         "No",
         "Yes"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>88.35</td>\n",
       "      <td>Month-to-Month</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>353.40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>36.67</td>\n",
       "      <td>Month-to-Month</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>63.79</td>\n",
       "      <td>Month-to-Month</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>127.58</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>8</td>\n",
       "      <td>102.34</td>\n",
       "      <td>One-Year</td>\n",
       "      <td>DSL</td>\n",
       "      <td>818.72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>69.01</td>\n",
       "      <td>Month-to-Month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2208.32</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Age  Gender  Tenure  MonthlyCharges    ContractType  \\\n",
       "0           1   49    Male       4           88.35  Month-to-Month   \n",
       "1           2   43    Male       0           36.67  Month-to-Month   \n",
       "2           3   51  Female       2           63.79  Month-to-Month   \n",
       "3           4   60  Female       8          102.34        One-Year   \n",
       "4           5   42    Male      32           69.01  Month-to-Month   \n",
       "\n",
       "  InternetService  TotalCharges TechSupport Churn  \n",
       "0     Fiber Optic        353.40         Yes   Yes  \n",
       "1     Fiber Optic          0.00         Yes   Yes  \n",
       "2     Fiber Optic        127.58          No   Yes  \n",
       "3             DSL        818.72         Yes   Yes  \n",
       "4             NaN       2208.32          No   Yes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "\n",
    "url_dataset = \"https://raw.githubusercontent.com/adisetiawannn/DataCraft/main/data/raw/dataset_preprocessing/customer_churn_data.csv\"\n",
    "\n",
    "df = pd.read_csv(url_dataset)\n",
    "\n",
    "# display the first five rows of the dataframe\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf200765",
   "metadata": {},
   "source": [
    "### **1. Cleaning Data : Handling Missing Value**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08adc033",
   "metadata": {},
   "source": [
    "Missing values are empty spots in your data—like blanks or NaNs—that can mess things up when training a model.\n",
    "\n",
    "- **Why Fix Them?**\n",
    "\n",
    "    Because most machine learning models don’t like missing data. If you ignore them, your model might crash or give bad predictions.\n",
    "\n",
    "- **How to Handle?**\n",
    "\n",
    "    - Drop them if they’re not important\n",
    "    \n",
    "    - Fill them with something like the mean, median, or a default value\n",
    "\n",
    "    - Use forward/backward fill for time-based data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aff4d14",
   "metadata": {},
   "source": [
    "Comparison Table of Handling Missing Value Techniques\n",
    "\n",
    "| Technique                     | When to Use                                                                 | Pros                                                                 | Cons                                                                 | How to Do                                                                                   |\n",
    "|--------------------------------|------------------------------------------------------------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|------------------------------------------------------------------------------------------------|\n",
    "| **Remove Missing Values**      | - Missing data is rare (<5% of dataset)                                      | - Simple and fast                                                    | - Can lose valuable information                                    | `df.dropna()`                                                                                 |\n",
    "|                                | - Missingness is random                                                      | - No risk of introducing bias from imputation                        | - Can reduce dataset size                                           |                                                                                                |\n",
    "| **Fill NA (Static Value) : mean, median, average and etc**     | - Missing data is more frequent but predictable                              | - Keeps all rows                                                      | - May introduce bias if fill value is not representative            | `df.fillna(0)` or `df.fillna(df['col'].mean())`                                                |\n",
    "|                                | - You have a meaningful constant or statistic (mean, median, mode)           | - Simple to implement                                                 | - Can reduce variance artificially                                  |                                                                                                |\n",
    "| **Forward/Backward Fill**      | - Time series or sequential data where last/next value makes sense           | - Preserves temporal consistency                                      | - Can propagate incorrect values forward/backward                   | `df.fillna(method='ffill')` (forward) or `df.fillna(method='bfill')` (backward)                |\n",
    "|                                | - Small gaps in data that should be smoothed                                 | - Good for short gaps in ordered data                                 | - Not suitable for large gaps                                       |                                                                                                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have missing values in the following columns: ['Age', 'City', 'Score']\n"
     ]
    }
   ],
   "source": [
    "# Create a sample DataFrame with missing values\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace', 'Hannah', 'Ian', 'Jane',\n",
    "             'Kevin', 'Laura', 'Mike', 'Nina', 'Oscar', 'Paula', 'Quinn', 'Rachel', 'Steve', 'Tina'],\n",
    "    'Age': [25, np.nan, 30, 22, np.nan, 28, 35, 40, np.nan, 29,\n",
    "            31, 27, np.nan, 33, 26, 24, 38, np.nan, 32, 30],\n",
    "    'City': ['Jakarta', 'Medan', np.nan, 'Bandung', 'Surabaya', 'Jakarta', 'Medan', 'Bandung', 'Surabaya', np.nan,\n",
    "             'Jakarta', 'Medan', 'Bandung', np.nan, 'Surabaya', 'Jakarta', 'Medan', 'Bandung', 'Surabaya', 'Jakarta'],\n",
    "    'Score': [88, 92, np.nan, 85, 90, 87, np.nan, 91, 89, 86,\n",
    "              93, np.nan, 84, 88, 90, 85, 92, 89, np.nan, 87]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# check column with missing values\n",
    "columns_with_missing = df.columns[df.isnull().any()].tolist() ; \n",
    "\n",
    "print(f\"we have missing values in the following columns:\", columns_with_missing);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c26d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name     0\n",
      "Age      5\n",
      "City     0\n",
      "Score    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. DROP Missing Values\n",
    "# from the info above, we can see that the InternetService column has missing values\n",
    "\n",
    "df_drop = df.dropna(subset=['City', 'Score'])\n",
    "null_counts = df_drop.isnull().sum()  # check null values after dropping rows\n",
    "print(null_counts) # display the DataFrame after dropping rows with missing values, now we have no missing values in the 'City' and 'Score' columns but still have missing values in the 'Age' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b540f04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Name   Age      City  Score  Age_mean  Score_median City_filled\n",
      "0     Alice  25.0   Jakarta   88.0      25.0          88.0     Jakarta\n",
      "1       Bob   NaN     Medan   92.0      30.0          92.0       Medan\n",
      "2   Charlie  30.0       NaN    NaN      30.0          88.5     Unknown\n",
      "3     David  22.0   Bandung   85.0      22.0          85.0     Bandung\n",
      "4       Eva   NaN  Surabaya   90.0      30.0          90.0    Surabaya\n",
      "5     Frank  28.0   Jakarta   87.0      28.0          87.0     Jakarta\n",
      "6     Grace  35.0     Medan    NaN      35.0          88.5       Medan\n",
      "7    Hannah  40.0   Bandung   91.0      40.0          91.0     Bandung\n",
      "8       Ian   NaN  Surabaya   89.0      30.0          89.0    Surabaya\n",
      "9      Jane  29.0       NaN   86.0      29.0          86.0     Unknown\n",
      "10    Kevin  31.0   Jakarta   93.0      31.0          93.0     Jakarta\n",
      "11    Laura  27.0     Medan    NaN      27.0          88.5       Medan\n",
      "12     Mike   NaN   Bandung   84.0      30.0          84.0     Bandung\n",
      "13     Nina  33.0       NaN   88.0      33.0          88.0     Unknown\n",
      "14    Oscar  26.0  Surabaya   90.0      26.0          90.0    Surabaya\n",
      "15    Paula  24.0   Jakarta   85.0      24.0          85.0     Jakarta\n",
      "16    Quinn  38.0     Medan   92.0      38.0          92.0       Medan\n",
      "17   Rachel   NaN   Bandung   89.0      30.0          89.0     Bandung\n",
      "18    Steve  32.0  Surabaya    NaN      32.0          88.5    Surabaya\n",
      "19     Tina  30.0   Jakarta   87.0      30.0          87.0     Jakarta\n"
     ]
    }
   ],
   "source": [
    "# 2. Fill missing numerical values with mean\n",
    "\n",
    "df['Age_mean'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Fill missing numerical values with median\n",
    "df['Score_median'] = df['Score'].fillna(df['Score'].median())\n",
    "\n",
    "# Fill missing categorical/string values with a default : Unknown\n",
    "df['City_filled'] = df['City'].fillna('Unknown')\n",
    "\n",
    "print(df)   # Display the DataFrame after filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25c137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Name  Age_ffill  Age_bfill\n",
      "0     Alice       25.0       25.0\n",
      "1       Bob       25.0       30.0\n",
      "2   Charlie       30.0       30.0\n",
      "3     David       22.0       22.0\n",
      "4       Eva       22.0       28.0\n",
      "5     Frank       28.0       28.0\n",
      "6     Grace       35.0       35.0\n",
      "7    Hannah       40.0       40.0\n",
      "8       Ian       40.0       29.0\n",
      "9      Jane       29.0       29.0\n",
      "10    Kevin       31.0       31.0\n",
      "11    Laura       27.0       27.0\n",
      "12     Mike       27.0       33.0\n",
      "13     Nina       33.0       33.0\n",
      "14    Oscar       26.0       26.0\n",
      "15    Paula       24.0       24.0\n",
      "16    Quinn       38.0       38.0\n",
      "17   Rachel       38.0       32.0\n",
      "18    Steve       32.0       32.0\n",
      "19     Tina       30.0       30.0\n"
     ]
    }
   ],
   "source": [
    "# 3. Forward/Backward Fill\n",
    "\n",
    "df['Age_ffill'] = df['Age'].ffill()  # Forward fill\n",
    "df['Age_bfill'] = df['Age'].bfill()  # Backward fill\n",
    "\n",
    "print(df[['Name','Age_ffill', 'Age_bfill']])  # Display the DataFrame with forward and backward filled values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a86536",
   "metadata": {},
   "source": [
    "### **2 Transforming Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fbedf",
   "metadata": {},
   "source": [
    "- **What is Transforming Data**\n",
    "\n",
    "    Before we feed data into a machine learning model, we often need to clean it up and reshape it a bit. That’s what data transformation is all about — making sure the data is in the right format and scale so the model can actually learn from it.\n",
    "\n",
    "    Think of it like prepping ingredients before cooking. You wouldn’t throw whole vegetables into a blender without chopping them first, right?\n",
    "\n",
    "- **Why we need to Transform our Data**\n",
    "\n",
    "  Machine learning models are picky. They work best when:\n",
    "\n",
    "  - a. Numbers are on similar scales  \n",
    "  - b. Categories are turned into something they can understand (like numbers)  \n",
    "  - c. Data is clean, consistent, and standardized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6694fb",
   "metadata": {},
   "source": [
    "- **How Do We Transform Data?**\n",
    "\n",
    "  | Technique Name     | Definition                                                                 | Popular Methods                                      | When to Use                                                                 | Pros                                                                 | Cons                                                                 | How to Do (Python Code)                                                                 |\n",
    "  |--------------------|-----------------------------------------------------------------------------|------------------------------------------------------|------------------------------------------------------------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|------------------------------------------------------------------------------------------|\n",
    "  | Scaling Values      | Adjusts numerical values to a common scale without changing distribution   | Min-Max Scaling, Robust Scaling, MaxAbs Scaling      | When features have different ranges (e.g., 0–1 vs 0–1000)                    | Helps models converge faster and treat features equally              | Doesn’t handle outliers well (MinMax), may distort data              | `MinMaxScaler().fit_transform(data)`<br>`RobustScaler().fit_transform(data)`            |\n",
    "  | Encoding Categories | Converts categorical data into numerical format                            | One-Hot Encoding, Label Encoding, Ordinal Encoding   | When you have non-numeric features like \"Yes\"/\"No\", \"Red\"/\"Blue\"            | Makes categorical data usable by ML models                           | Can increase dimensionality (One-Hot), may imply order (Label)       | `LabelEncoder().fit_transform(data)`<br>`pd.get_dummies(data)`<br>`OrdinalEncoder()`    |\n",
    "  | Normalizing         | Scales data to a fixed range, usually [0, 1]                               | Min-Max Normalization, L2 Normalization, MaxAbs      | When data needs to be bounded or when using distance-based models           | Keeps data within a consistent range                                 | Sensitive to outliers                                                | `MinMaxScaler().fit_transform(data)`<br>`normalize(data, norm='l2')`                    |\n",
    "  | Standardizing       | Centers data around mean 0 and std dev 1                                   | Z-score Standardization, Robust Scaling, PowerTransform | When data has varying distributions or outliers                             | Handles outliers better than normalization                           | Assumes Gaussian distribution (may not fit all data)                 | `StandardScaler().fit_transform(data)`<br>`RobustScaler().fit_transform(data)`          |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deab361",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
